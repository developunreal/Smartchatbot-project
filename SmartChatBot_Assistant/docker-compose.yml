version: "3.8"

services:
  ollama:
    image: ollama/ollama:latest
    container_name: ollama
    environment:
      - OLLAMA_HOST=0.0.0.0:11444
      - OLLAMA_ORIGINS=*
    volumes:
      - ollama_data:/root/.ollama
    ports:
      - "11444:11434"   # host:container port mapping
    restart: unless-stopped

  # This service runs once to ensure the model is downloaded
  ollama-init:
    image: ollama/ollama:latest
    depends_on:
      - ollama
    entrypoint: ["ollama", "pull", "smollm2:135m"]
    volumes:
      - ollama_data:/root/.ollama
    restart: "no"

  fastapi:
    build:
      context: ./fastapi
    container_name: smartchat
    depends_on:
      - ollama
      - ollama-init   # ensure model is pulled before FastAPI starts
    environment:
      - OLLAMA_URL=http://ollama:11444
      - OLLAMA_MODEL=smollm2:135m
    ports:
      - "8081:8081"
    restart: unless-stopped

volumes:
  ollama_data:

